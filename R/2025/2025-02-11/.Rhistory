rm(list = ls())
gc()
# load libraries -------
library(data.table)
library(ggplot2)
library(stringr)
library(extrafont)
library(colorspace)
library(ggtext)
cdc_datasets <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/cdc_datasets.csv')
fpi_codes <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/fpi_codes.csv')
omb_codes <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/omb_codes.csv')
View(cdc_datasets)
library(ggplot2)
library(dplyr)
cdc_data <- read.csv("cdc_datasets.csv")
library(ggplot2)
library(data.table)
# Count datasets per bureau
bureau_counts <- cdc_datasets[, .N, by = bureau_code][order(-N)]
ggplot(bureau_counts, aes(x = reorder(bureau_code, N), y = N)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Number of Archived Datasets per Bureau",
x = "Bureau Code",
y = "Number of Datasets") +
theme_minimal()
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
library(tm)
install.packages("tm")
library(wordcloud)
library(tm)
# Extract and split tags
tag_words <- unlist(strsplit(tolower(paste(cdc_datasets$tags, collapse = " ")), ", "))
# Count word frequency
tag_freq <- table(tag_words)
# Create word cloud
wordcloud(names(tag_freq), freq = tag_freq, min.freq = 5, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
access_counts <- cdc_datasets[, .N, by = public_access_level][order(-N)]
ggplot(access_counts, aes(x = reorder(public_access_level, N), y = N, fill = public_access_level)) +
geom_col() +
labs(title = "Public Access Level of Archived Datasets",
x = "Access Level",
y = "Number of Datasets") +
theme_minimal()
library(leaflet)
# Extract unique locations
locations <- cdc_datasets[!is.na(geographic_coverage), unique(geographic_coverage)]
leaflet() %>%
addTiles() %>%
addMarkers(data = locations, popup = ~locations)
cdc_datasets[, issued := as.Date(issued)]  # Convert to Date format
ggplot(cdc_datasets[!is.na(issued)], aes(x = issued)) +
geom_histogram(binwidth = 365, fill = "darkred", alpha = 0.7) +
labs(title = "Trend of Dataset Issuance Over Time",
x = "Year",
y = "Number of Datasets") +
theme_minimal()
library(scales)
# Count by public access level and year
access_trend <- cdc_datasets[, .N, by = .(public_access_level, year = year(as.Date(issued)))]
ggplot(access_trend, aes(x = year, y = N, fill = public_access_level)) +
geom_col(position = "dodge") +
scale_x_continuous(breaks = seq(2000, 2025, 5)) +
scale_fill_manual(values = c("public" = "green", "restricted public" = "orange", "non-public" = "red")) +
labs(title = "Public Access Level Over Time",
x = "Year",
y = "Number of Datasets") +
theme_minimal()
library(ComplexHeatmap)
# Create a matrix of dataset counts per program_code and public_access_level
heatmap_data <- dcast(cdc_datasets, program_code ~ public_access_level, fun.aggregate = length)
# Convert to matrix
heatmap_matrix <- as.matrix(heatmap_data[, -1])
# Plot heatmap
Heatmap(heatmap_matrix, name = "Dataset Count", col = colorRampPalette(c("white", "red"))(10))
rm(list = ls())
gc()
cdc_datasets <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/cdc_datasets.csv')
fpi_codes <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/fpi_codes.csv')
omb_codes <- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/omb_codes.csv')
View(fpi_codes)
View(cdc_datasets)
cdc_datasets |> head()
unique(cdc_datasets$category)
sub(".*/", "", cdc_datasets$dataset_url) |> head()
unique(cdc_datasets$tags)
unique(cdc_datasets$tags) |> length()
unique(cdc_datasets$category) |> length()
cdc_datasets$category |> unique() |> length()
cdc_datasets$category |> unique()
